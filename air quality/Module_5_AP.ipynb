{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5 : Performance measurements of  K-Nearest Neighbor and Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library packages\n",
    "import pandas as p\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as s\n",
    "import numpy as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=p.read_excel(\"AirQuality.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['Country','State','city','place','lastupdate','Avg','Max','Min','Pollutants']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AQI'] = df.Avg.map({ '68':'satisfactor', '74':'satisfactor', '71':'satisfactor', '4':'good', '39':'good', '42':'good', '27':'good', '263':'poor', '250':'poor', '249':'poor','258':'poor', '284':'poor', '28':'good', '106':'satisfactor', '44':'good', '62':'satisfactor', '59':'satisfactor', '1':'good', '9':'good', '15':'good', '34':'good','63':'satisfactor', '14':'good', '13':'good', '69':'satisfactor', '37':'good', '2':'good', '5':'good', '66':'satisfactor', '202':'poor', '11':'good', '10':'good','52':'satisfactor', '54':'satisfactor', '246':'poor', '248':'poor', '32':'good', '93':'satisfactor', '226':'poor', '189':'moderate', '124':'moderate', '272':'poor','277':'poor', '278':'poor', '279':'poor', '280':'poor', '87':'satisfactor', '19':'good', '240':'poor', '197':'moderate', '38':'good', '84':'satisfactor','61':'satisfactor', '196':'moderate', '171':'moderate', '23' :'good', '111':'moderate', '43' :'good', '188':'moderate', '203' :'poor' , '16' :'good', '20' :'good','225' :'poor' , '190':'moderate', '26' :'good', '104':'moderate', '25' :'good', '224' :'poor' , '210' :'poor' , '83':'satisfactor', '82':'satisfactor', '233' :'poor' ,'205' :'poor' , '78':'satisfactor', '70':'satisfactor', '211' :'poor' , '179':'moderate', '91':'satisfactor', '49':'good', '134':'moderate', '161':'moderate', '223' :'poor' ,'57':'satisfactor', '73':'satisfactor', '207' :'poor' , '184':'moderate', '48' :'good', '6' :'good', '7' :'good', '194':'moderate', '21' :'good', '50' :'good', '231' :'poor' ,'175':'moderate', '45' :'good', '86':'satisfactor', '243' :'poor' , '232' :'poor' , '18' :'good', '31' :'good', '95':'satisfactor', '237' :'poor' , '217' :'poor' ,'99':'satisfactor', '33' :'good', '176':'moderate', '22' :'good', '29' :'good', '107':'moderate', '17' :'good', '75':'satisfactor', '220' :'poor' , '165':'moderate','149':'moderate', '3' :'good', '245' :'poor' , '239' :'poor' , '72':'satisfactor', '77':'satisfactor', '208' :'poor' , '24' :'good', '198':'moderate', '153':'moderate','53':'satisfactor', '228' :'poor' , '186':'moderate', '51':'satisfactor', '247' :'poor' , '219' :'poor' , '100':'satisfactor', '36' :'good', '204' :'poor' , '30' :'good','221' :'poor' , '229' :'poor' , '187':'moderate', '56':'satisfactor', '230' :'poor' , '192':'moderate', '114':'moderate', '274' :'poor' , '236' :'poor' ,'222' :'poor' , '206' :'poor' , '174':'moderate', '58':'satisfactor', '235' :'poor' , '212' :'poor' , '120':'moderate', '148':'moderate', '242' :'poor' ,'215' :'poor' , '80':'satisfactor', '79':'satisfactor', '67':'satisfactor', '40' :'good', '35' :'good', '185':'moderate', '101':'moderate', '46' :'good', '209' :'poor' ,'169':'moderate', '12' :'good', '47' :'good', '227' :'poor' , '200' :'moderate' , '244' :'poor' , '238' :'poor' , '160':'moderate', '282' :'poor' , '218' :'poor' ,'261' :'poor' , '262' :'poor' , '260' :'poor' , '256' :'poor' , '252' :'poor' , '162':'moderate', '172':'moderate', '156':'moderate', '133':'moderate','116':'moderate', '193':'moderate', '123':'moderate', '65':'satisfactor', '96':'satisfactor', '173':'moderate', '103':'moderate', '8' :'good', '273' :'poor' , '275' :'poor' ,'283' :'poor' , '276' :'poor' , '254' :'poor' , '152':'moderate', '105':'moderate', '64':'satisfactor', '0' :'good', '76':'satisfactor', '127':'moderate', '97':'satisfactor','115':'moderate', '150':'moderate', '142':'moderate', '41' :'good', '102':'moderate', '90':'satisfactor', '132':'moderate', '98':'satisfactor', '199':'moderate', '191':'moderate','157':'moderate', '139':'moderate', '94':'satisfactor', '110':'moderate', '270' :'poor' , '268' :'poor' , '281' :'poor' , '265' :'poor' , '267' :'poor' ,'269' :'poor' , '81':'satisfactor', '128':'moderate', '146':'moderate', '145':'moderate', '129':'moderate', '85':'satisfactor', '117':'moderate', '108':'moderate', '154':'moderate','131':'moderate', '255' :'poor' , '257' :'poor' , '88':'satisfactor', '113':'moderate', '118':'moderate', '167':'moderate', '164':'moderate', '137':'moderate','135':'moderate', '138':'moderate', '109':'moderate', '60':'satisfactor', '177':'moderate', '271' :'poor' , '170':'moderate', '144':'moderate', '166':'moderate','155':'moderate', '136':'moderate', '151':'moderate', '89':'satisfactor', '119':'moderate', '266' :'poor' , '264' :'poor' , '251' :'poor' , '253' :'poor' ,'259' :'poor' , '163':'moderate', '159':'moderate', '241' :'poor' , '214' :'poor' , '122':'moderate', '234' :'poor' , '195':'moderate', '130':'moderate','216' :'poor' , '213' :'poor' , '121':'moderate', '112':'moderate', '168':'moderate', '201' :'poor' , '141':'moderate', '181':'moderate', '143':'moderate','126':'moderate', '182':'moderate', '178':'moderate', '158':'moderate', '140':'moderate', '183':'moderate', '92':'satisfactor', '180':'moderate', '147':'moderate', '55':'satisfactor','125':'moderate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df.AQI.map({'good':1,'moderate':0, 'servere':0, 'verypoor':0, 'satisfactor':1,'poor':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['AQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the cross-validated MCC scores, the random forest is the best-performing model, so now let's evaluate its performance on the test set.\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='class', axis=1)\n",
    "#Response variable\n",
    "y = df.loc[:,'class']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We'll use a test size of 30%. We also stratify the split on the response variable, which is very important to do because there are so few fraudulent transactions.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of K-Nearest Neighbor Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97        73\n",
      "           1       0.99      0.98      0.99       175\n",
      "\n",
      "    accuracy                           0.98       248\n",
      "   macro avg       0.97      0.98      0.98       248\n",
      "weighted avg       0.98      0.98      0.98       248\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97        73\n",
      "           1       0.99      0.98      0.99       175\n",
      "\n",
      "    accuracy                           0.98       248\n",
      "   macro avg       0.97      0.98      0.98       248\n",
      "weighted avg       0.98      0.98      0.98       248\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[1.         1.         1.         1.         0.91666667 1.\n",
      " 0.91666667 1.         0.91666667 1.         0.91666667 1.\n",
      " 1.         1.         1.         1.         0.83333333 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.91666667 1.         0.83333333 1.         1.\n",
      " 0.91666667 1.         1.         0.91666667 1.         1.\n",
      " 0.91666667 1.         1.         0.91666667 1.         0.91666667\n",
      " 1.         1.         1.         0.75       1.         1.\n",
      " 1.         1.         0.90909091 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "\n",
      "\n",
      "Accuracy result of K-Nearest Neighbor is: 97.84632034632034\n",
      "\n",
      "Confusion Matrix result of K-Nearest Neighbor is:\n",
      " [[ 71   2]\n",
      " [  3 172]]\n",
      "\n",
      "Sensitivity :  0.9726027397260274\n",
      "\n",
      "Specificity :  0.9828571428571429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnc = KNeighborsClassifier()\n",
    "\n",
    "knnc.fit(X_train,y_train)\n",
    "\n",
    "predictR = knnc.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of K-Nearest Neighbor Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "accuracy = cross_val_score(knnc, X, y, cv=70)\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "print(\"\")\n",
    "\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of K-Nearest Neighbor is:\",accuracy.mean() * 100)\n",
    "print(\"\")\n",
    "\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of K-Nearest Neighbor is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive : 172\n",
      "True Negative : 71\n",
      "False Positive : 2\n",
      "False Negative : 3\n",
      "\n",
      "True Positive Rate : 0.9828571428571429\n",
      "True Negative Rate : 0.9726027397260274\n",
      "False Positive Rate : 0.0273972602739726\n",
      "False Negative Rate : 0.017142857142857144\n",
      "\n",
      "Positive Predictive Value : 0.9885057471264368\n",
      "Negative predictive value : 0.9594594594594594\n"
     ]
    }
   ],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Decision Tree Classifier Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        73\n",
      "           1       1.00      1.00      1.00       175\n",
      "\n",
      "    accuracy                           1.00       248\n",
      "   macro avg       1.00      1.00      1.00       248\n",
      "weighted avg       1.00      1.00      1.00       248\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.91666667 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "\n",
      "\n",
      "Accuracy result of Decision Tree Classifier is: 99.88095238095237\n",
      "\n",
      "Confusion Matrix result of Decision Tree Classifier is:\n",
      " [[ 73   0]\n",
      " [  0 175]]\n",
      "\n",
      "Sensitivity :  1.0\n",
      "\n",
      "Specificity :  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "predictDT = dtree.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Decision Tree Classifier Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictDT))\n",
    "accuracy = cross_val_score(dtree, X, y, cv=70)\n",
    "\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of Decision Tree Classifier is:\",accuracy.mean() * 100)\n",
    "print(\"\")\n",
    "\n",
    "cm1=confusion_matrix(y_test,predictDT)\n",
    "print('Confusion Matrix result of Decision Tree Classifier is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive : 175\n",
      "True Negative : 73\n",
      "False Positive : 0\n",
      "False Negative : 0\n",
      "\n",
      "True Positive Rate : 1.0\n",
      "True Negative Rate : 1.0\n",
      "False Positive Rate : 0.0\n",
      "False Negative Rate : 0.0\n",
      "\n",
      "Positive Predictive Value : 1.0\n",
      "Negative predictive value : 1.0\n"
     ]
    }
   ],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
