{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 : Performance measurements of Logistic regression and Naive Bayes algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library packages\n",
    "import pandas as p\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as s\n",
    "import numpy as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=p.read_excel(\"AirQuality.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'State', 'city', 'place', 'lastupdate', 'Avg', 'Max', 'Min',\n",
       "       'Pollutants'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['Country','State','city','place','lastupdate','Avg','Max','Min','Pollutants']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AQI'] = df.Avg.map({ '68':'satisfactor', '74':'satisfactor', '71':'satisfactor', '4':'good', '39':'good', '42':'good', '27':'good', '263':'poor', '250':'poor', '249':'poor','258':'poor', '284':'poor', '28':'good', '106':'satisfactor', '44':'good', '62':'satisfactor', '59':'satisfactor', '1':'good', '9':'good', '15':'good', '34':'good','63':'satisfactor', '14':'good', '13':'good', '69':'satisfactor', '37':'good', '2':'good', '5':'good', '66':'satisfactor', '202':'poor', '11':'good', '10':'good','52':'satisfactor', '54':'satisfactor', '246':'poor', '248':'poor', '32':'good', '93':'satisfactor', '226':'poor', '189':'moderate', '124':'moderate', '272':'poor','277':'poor', '278':'poor', '279':'poor', '280':'poor', '87':'satisfactor', '19':'good', '240':'poor', '197':'moderate', '38':'good', '84':'satisfactor','61':'satisfactor', '196':'moderate', '171':'moderate', '23' :'good', '111':'moderate', '43' :'good', '188':'moderate', '203' :'poor' , '16' :'good', '20' :'good','225' :'poor' , '190':'moderate', '26' :'good', '104':'moderate', '25' :'good', '224' :'poor' , '210' :'poor' , '83':'satisfactor', '82':'satisfactor', '233' :'poor' ,'205' :'poor' , '78':'satisfactor', '70':'satisfactor', '211' :'poor' , '179':'moderate', '91':'satisfactor', '49':'good', '134':'moderate', '161':'moderate', '223' :'poor' ,'57':'satisfactor', '73':'satisfactor', '207' :'poor' , '184':'moderate', '48' :'good', '6' :'good', '7' :'good', '194':'moderate', '21' :'good', '50' :'good', '231' :'poor' ,'175':'moderate', '45' :'good', '86':'satisfactor', '243' :'poor' , '232' :'poor' , '18' :'good', '31' :'good', '95':'satisfactor', '237' :'poor' , '217' :'poor' ,'99':'satisfactor', '33' :'good', '176':'moderate', '22' :'good', '29' :'good', '107':'moderate', '17' :'good', '75':'satisfactor', '220' :'poor' , '165':'moderate','149':'moderate', '3' :'good', '245' :'poor' , '239' :'poor' , '72':'satisfactor', '77':'satisfactor', '208' :'poor' , '24' :'good', '198':'moderate', '153':'moderate','53':'satisfactor', '228' :'poor' , '186':'moderate', '51':'satisfactor', '247' :'poor' , '219' :'poor' , '100':'satisfactor', '36' :'good', '204' :'poor' , '30' :'good','221' :'poor' , '229' :'poor' , '187':'moderate', '56':'satisfactor', '230' :'poor' , '192':'moderate', '114':'moderate', '274' :'poor' , '236' :'poor' ,'222' :'poor' , '206' :'poor' , '174':'moderate', '58':'satisfactor', '235' :'poor' , '212' :'poor' , '120':'moderate', '148':'moderate', '242' :'poor' ,'215' :'poor' , '80':'satisfactor', '79':'satisfactor', '67':'satisfactor', '40' :'good', '35' :'good', '185':'moderate', '101':'moderate', '46' :'good', '209' :'poor' ,'169':'moderate', '12' :'good', '47' :'good', '227' :'poor' , '200' :'moderate' , '244' :'poor' , '238' :'poor' , '160':'moderate', '282' :'poor' , '218' :'poor' ,'261' :'poor' , '262' :'poor' , '260' :'poor' , '256' :'poor' , '252' :'poor' , '162':'moderate', '172':'moderate', '156':'moderate', '133':'moderate','116':'moderate', '193':'moderate', '123':'moderate', '65':'satisfactor', '96':'satisfactor', '173':'moderate', '103':'moderate', '8' :'good', '273' :'poor' , '275' :'poor' ,'283' :'poor' , '276' :'poor' , '254' :'poor' , '152':'moderate', '105':'moderate', '64':'satisfactor', '0' :'good', '76':'satisfactor', '127':'moderate', '97':'satisfactor','115':'moderate', '150':'moderate', '142':'moderate', '41' :'good', '102':'moderate', '90':'satisfactor', '132':'moderate', '98':'satisfactor', '199':'moderate', '191':'moderate','157':'moderate', '139':'moderate', '94':'satisfactor', '110':'moderate', '270' :'poor' , '268' :'poor' , '281' :'poor' , '265' :'poor' , '267' :'poor' ,'269' :'poor' , '81':'satisfactor', '128':'moderate', '146':'moderate', '145':'moderate', '129':'moderate', '85':'satisfactor', '117':'moderate', '108':'moderate', '154':'moderate','131':'moderate', '255' :'poor' , '257' :'poor' , '88':'satisfactor', '113':'moderate', '118':'moderate', '167':'moderate', '164':'moderate', '137':'moderate','135':'moderate', '138':'moderate', '109':'moderate', '60':'satisfactor', '177':'moderate', '271' :'poor' , '170':'moderate', '144':'moderate', '166':'moderate','155':'moderate', '136':'moderate', '151':'moderate', '89':'satisfactor', '119':'moderate', '266' :'poor' , '264' :'poor' , '251' :'poor' , '253' :'poor' ,'259' :'poor' , '163':'moderate', '159':'moderate', '241' :'poor' , '214' :'poor' , '122':'moderate', '234' :'poor' , '195':'moderate', '130':'moderate','216' :'poor' , '213' :'poor' , '121':'moderate', '112':'moderate', '168':'moderate', '201' :'poor' , '141':'moderate', '181':'moderate', '143':'moderate','126':'moderate', '182':'moderate', '178':'moderate', '158':'moderate', '140':'moderate', '183':'moderate', '92':'satisfactor', '180':'moderate', '147':'moderate', '55':'satisfactor','125':'moderate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df.AQI.map({'good':1,'moderate':0, 'servere':0, 'verypoor':0, 'satisfactor':1,'poor':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['AQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>city</th>\n",
       "      <th>place</th>\n",
       "      <th>lastupdate</th>\n",
       "      <th>Avg</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Pollutants</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>105</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>99</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>115</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country State city place lastupdate Avg  Max Min Pollutants  class\n",
       "0       0     0    4   101          0  68  105  41          5      1\n",
       "1       0     0    4   101          0  74   99  42          4      1\n",
       "2       0     0    4   101          0  71  115  45          2      1\n",
       "3       0     0    4   101          0   4    5   3          1      1\n",
       "4       0     0    4   101          0  39  106   1          6      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'State', 'city', 'place', 'lastupdate', 'Avg', 'Max', 'Min',\n",
       "       'Pollutants', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the cross-validated MCC scores, the random forest is the best-performing model, so now let's evaluate its performance on the test set.\n",
    "from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='class', axis=1)\n",
    "#Response variable\n",
    "y = df.loc[:,'class']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Logistic Regression Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        73\n",
      "           1       0.99      0.99      0.99       175\n",
      "\n",
      "    accuracy                           0.99       248\n",
      "   macro avg       0.98      0.99      0.99       248\n",
      "weighted avg       0.99      0.99      0.99       248\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[0.91666667 1.         1.         1.         1.         1.\n",
      " 1.         1.         0.91666667 1.         1.         1.\n",
      " 1.         1.         1.         1.         0.91666667 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         0.91666667 1.         1.\n",
      " 1.         1.         1.         0.91666667 1.         1.\n",
      " 1.         0.91666667 1.         0.91666667 1.         0.91666667\n",
      " 0.91666667 1.         1.         1.         1.         1.\n",
      " 0.91666667 1.         1.         0.83333333 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.90909091 1.         1.         1.        ]\n",
      "\n",
      "\n",
      "Accuracy result of Logistic Regression is: 98.44155844155844\n",
      "\n",
      "Confusion Matrix result of Logistic Regression is:\n",
      " [[ 72   1]\n",
      " [  2 173]]\n",
      "\n",
      "Sensitivity :  0.9863013698630136\n",
      "\n",
      "Specificity :  0.9885714285714285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logR= LogisticRegression()\n",
    "\n",
    "logR.fit(X_train,y_train)\n",
    "\n",
    "predictR = logR.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Logistic Regression Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "\n",
    "accuracy = cross_val_score(logR, X, y, cv=70)\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "print(\"\")\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of Logistic Regression is:\",accuracy.mean() * 100)\n",
    "print(\"\")\n",
    "\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Logistic Regression is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive : 173\n",
      "True Negative : 72\n",
      "False Positive : 1\n",
      "False Negative : 2\n",
      "\n",
      "True Positive Rate : 0.9885714285714285\n",
      "True Negative Rate : 0.9863013698630136\n",
      "False Positive Rate : 0.0136986301369863\n",
      "False Negative Rate : 0.011428571428571429\n",
      "\n",
      "Positive Predictive Value : 0.9942528735632183\n",
      "Negative predictive value : 0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report of Naive Bayes Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        73\n",
      "           1       0.99      0.97      0.98       175\n",
      "\n",
      "    accuracy                           0.98       248\n",
      "   macro avg       0.96      0.98      0.97       248\n",
      "weighted avg       0.98      0.98      0.98       248\n",
      "\n",
      "Cross validation test results of accuracy:\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.91666667 1.         1.         1.\n",
      " 1.         1.         0.91666667 1.         0.91666667 1.\n",
      " 1.         1.         0.91666667 1.         1.         1.\n",
      " 0.91666667 1.         1.         0.91666667 1.         0.91666667\n",
      " 1.         0.91666667 0.91666667 1.         1.         0.91666667\n",
      " 0.91666667 0.83333333 1.         0.91666667 1.         1.\n",
      " 0.83333333 1.         0.91666667 1.         1.         1.\n",
      " 0.91666667 1.         1.         0.83333333 1.         1.\n",
      " 1.         1.         0.90909091 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "\n",
      "\n",
      "Accuracy result of Naive Bayes is: 97.48917748917751\n",
      "\n",
      "Confusion Matrix result of Naive Bayes is:\n",
      " [[ 72   1]\n",
      " [  5 170]]\n",
      "\n",
      "Sensitivity :  0.9863013698630136\n",
      "\n",
      "Specificity :  0.9714285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train,y_train)\n",
    "\n",
    "predictR = gnb.predict(X_test)\n",
    "\n",
    "print(\"\")\n",
    "print('Classification report of Naive Bayes Results:')\n",
    "print(\"\")\n",
    "\n",
    "print(classification_report(y_test,predictR))\n",
    "accuracy = cross_val_score(gnb, X, y, cv=70)\n",
    "print('Cross validation test results of accuracy:')\n",
    "print(accuracy)\n",
    "print(\"\")\n",
    "\n",
    "#get the mean of each fold \n",
    "print(\"\")\n",
    "print(\"Accuracy result of Naive Bayes is:\",accuracy.mean() * 100)\n",
    "print(\"\")\n",
    "cm1=confusion_matrix(y_test,predictR)\n",
    "print('Confusion Matrix result of Naive Bayes is:\\n',cm1)\n",
    "print(\"\")\n",
    "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "print(\"\")\n",
    "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive : 170\n",
      "True Negative : 72\n",
      "False Positive : 1\n",
      "False Negative : 5\n",
      "\n",
      "True Positive Rate : 0.9714285714285714\n",
      "True Negative Rate : 0.9863013698630136\n",
      "False Positive Rate : 0.0136986301369863\n",
      "False Negative Rate : 0.02857142857142857\n",
      "\n",
      "Positive Predictive Value : 0.9941520467836257\n",
      "Negative predictive value : 0.935064935064935\n"
     ]
    }
   ],
   "source": [
    "TN = cm1[0][0]\n",
    "FN = cm1[1][0]\n",
    "TP = cm1[1][1]\n",
    "FP = cm1[0][1]\n",
    "print(\"True Positive :\",TP)\n",
    "print(\"True Negative :\",TN)\n",
    "print(\"False Positive :\",FP)\n",
    "print(\"False Negative :\",FN)\n",
    "print(\"\")\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"True Positive Rate :\",TPR)\n",
    "print(\"True Negative Rate :\",TNR)\n",
    "print(\"False Positive Rate :\",FPR)\n",
    "print(\"False Negative Rate :\",FNR)\n",
    "print(\"\")\n",
    "PPV = TP/(TP+FP)\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"Positive Predictive Value :\",PPV)\n",
    "print(\"Negative predictive value :\",NPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
